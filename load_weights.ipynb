{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6000 TRAIN, 4000 TEST\n",
    "#no signal (0) BLUE , electron/positron (1) GREEN , another kind of particles (2) YELLOW\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tables\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "train_file = '/u/gl/tedeschi/phase1/dataset/train_1-2.hdf5'\n",
    "#test_file = '/~/phase1/dataset/test_1-2.hdf5'\n",
    "#submission_file = 'submission_1-2.hdf5'\n",
    "\n",
    "f=tables.open_file(train_file, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_events(start_index=0, end_index=100):\n",
    "    X_train, y_train, w_train = [], [], []\n",
    "    for event_index in trange(start_index, end_index):\n",
    "        data_hits = np.array(f.root.data[event_index : event_index + 1])\n",
    "        data_labels=np.array(f.root.label[event_index : event_index + 1],dtype=np.int64)\n",
    "        data_weights = np.zeros([1,192,192,192],dtype=np.float32)\n",
    "        vals, counts = np.unique(data_labels,return_counts=True)\n",
    "        for i, val in enumerate(vals):\n",
    "            if val==0:\n",
    "                data_weights[np.where(data_labels == val)] = 0.\n",
    "            else:\n",
    "                data_weights[np.where(data_labels == val)] = 1. / counts[i] / len(vals)\n",
    "        X_train.append(data_hits)\n",
    "        y_train.append(data_labels)\n",
    "        w_train.append(data_weights)\n",
    "    return np.concatenate(X_train), np.concatenate(y_train), np.concatenate(w_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import commands,sys,os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "import tensorflow.contrib.layers as L\n",
    "import tensorflow.contrib.slim as slim\n",
    "IMAGE_SIZE=192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_test(num_images,X,y,w):\n",
    "    images_plot, labels_plot, weights_plot, preds_plot, probs_plot = sess.run([images, labels, weights, prediction, softmax], feed_dict={images: X,\n",
    "                                                                                                                                         labels: y,\n",
    "                                                                                                                                         weights: w})\n",
    "    \n",
    "    if num_images is None or num_images > len(images_plot):\n",
    "        num_images = len(images_plot)\n",
    "    \n",
    "    for index in range(num_images):\n",
    "        print \"ENERGY DEPOSITION\"\n",
    "        fig=plt.figure()\n",
    "        crop=images_plot[index].reshape([IMAGE_SIZE,IMAGE_SIZE,IMAGE_SIZE])\n",
    "        ax = fig.add_subplot(111,projection='3d')\n",
    "        x,y,z = np.where(crop>0)\n",
    "        v=crop[crop>0]\n",
    "        cv = ax.scatter(x,y,z,c=v, marker='o', vmin=0,vmax=40)\n",
    "        plt.colorbar(cv)\n",
    "        plt.show()\n",
    "    \n",
    "        print \"LABELS\"\n",
    "        fig=plt.figure()\n",
    "        data_labels=labels_plot[index].reshape([IMAGE_SIZE,IMAGE_SIZE,IMAGE_SIZE])\n",
    "        ax = fig.add_subplot(111,projection='3d')\n",
    "        x,y,z = np.where(crop>0)\n",
    "        v=data_labels[crop>0]\n",
    "        cl = ax.scatter(x,y,z,c=v, marker='o', vmin=0,vmax=2)\n",
    "        plt.colorbar(cl)\n",
    "        plt.show()\n",
    "        print np.unique(data_labels,return_counts=True)\n",
    "        \n",
    "        print \"WEIGHTS\"\n",
    "        fig=plt.figure()\n",
    "        data_labels=weights_plot[index].reshape([IMAGE_SIZE,IMAGE_SIZE,IMAGE_SIZE])\n",
    "        ax = fig.add_subplot(111,projection='3d')\n",
    "        x,y,z = np.where(crop>0)\n",
    "        v=data_labels[crop>0]\n",
    "        cl = ax.scatter(x,y,z,c=v, marker='o', vmin=1e-4,vmax=1e-3)\n",
    "        plt.colorbar(cl)\n",
    "        plt.show()\n",
    "        print np.unique(data_labels,return_counts=True)\n",
    "        \n",
    "        print \"PREDICTION\"\n",
    "        fig=plt.figure()\n",
    "        data_labels=preds_plot[index].reshape([IMAGE_SIZE,IMAGE_SIZE,IMAGE_SIZE])\n",
    "        ax = fig.add_subplot(111,projection='3d')\n",
    "        x,y,z = np.where(crop>0)\n",
    "        v=data_labels[crop>0]\n",
    "        cl = ax.scatter(x,y,z,c=v, marker='o', vmin=0,vmax=2)\n",
    "        plt.colorbar(cl)\n",
    "        plt.show()\n",
    "        print np.unique(data_labels,return_counts=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"input\"):\n",
    "    images  = tf.placeholder(tf.float32, [None, 192, 192, 192])\n",
    "    labels  = tf.placeholder(tf.int64,   [None, 192, 192, 192])\n",
    "    weights = tf.placeholder(tf.float32, [None, 192, 192, 192])\n",
    "    images3D = tf.reshape(images, [-1, 192, 192, 192, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_resnet_module(input_tensor, num_outputs, trainable=True, kernel=(3,3,3), stride=1, scope='noscope'):\n",
    "\n",
    "    fn_conv = slim.conv3d\n",
    "\n",
    "    num_inputs  = input_tensor.get_shape()[-1].value\n",
    "    with tf.variable_scope(scope):\n",
    "        shortcut = None\n",
    "        if num_outputs == num_inputs and stride ==1 :\n",
    "            shortcut = input_tensor\n",
    "        else:\n",
    "            shortcut = slim.conv3d(inputs      = input_tensor,\n",
    "                                   num_outputs = num_outputs,\n",
    "                                   kernel_size = 1,\n",
    "                                   stride      = stride,\n",
    "                                   normalizer_fn = slim.batch_norm,\n",
    "                                   activation_fn = None,\n",
    "                                   trainable   = trainable,\n",
    "                                   scope       = 'shortcut')\n",
    "        residual = slim.conv3d(inputs      = input_tensor,\n",
    "                               num_outputs = num_outputs,\n",
    "                               kernel_size = kernel,\n",
    "                               stride      = stride,\n",
    "                               normalizer_fn = slim.batch_norm,\n",
    "                               #activation_fn = None,\n",
    "                               trainable   = trainable,\n",
    "                               scope       = 'resnet_conv1')\n",
    "        \n",
    "        residual = slim.conv3d(inputs      = residual,\n",
    "                               num_outputs = num_outputs,\n",
    "                               kernel_size = kernel,\n",
    "                               normalizer_fn = slim.batch_norm,\n",
    "                               activation_fn = None,\n",
    "                               trainable   = trainable,\n",
    "                               scope       = 'resnet_conv2')\n",
    "        \n",
    "        return tf.nn.relu(shortcut + residual)\n",
    "\n",
    "def double_toy_resnet(input_tensor, num_outputs, trainable=True, kernel=3, stride=1, scope='noscope'):\n",
    "\n",
    "    with tf.variable_scope(scope):\n",
    "\n",
    "        resnet1 = toy_resnet_module(input_tensor=input_tensor,\n",
    "                                    trainable=trainable,\n",
    "                                    kernel=kernel,\n",
    "                                    stride=stride,\n",
    "                                    num_outputs=num_outputs,\n",
    "                                    scope='module1')\n",
    "        \n",
    "        resnet2 = toy_resnet_module(input_tensor=resnet1,\n",
    "                                    trainable=trainable,\n",
    "                                    kernel=kernel,\n",
    "                                    stride=1,\n",
    "                                    num_outputs=num_outputs,\n",
    "                                    scope='module2')\n",
    "\n",
    "        return resnet2\n",
    "\n",
    "def toy_uresnet(input_tensor, num_class, reuse=False, trainable=True, base_filter=16, num_contraction=4):\n",
    "\n",
    "    with tf.variable_scope('toy_uresnet', reuse=reuse):\n",
    "    \n",
    "        conv_feature_map={}\n",
    "        net = input_tensor\n",
    "        print('Input shape {:s}'.format(net.shape))\n",
    "\n",
    "        # 1st conv layer normal\n",
    "        net = slim.conv3d     (net, base_filter, 3, normalizer_fn=slim.batch_norm, trainable=trainable, scope='conv0')\n",
    "        conv_feature_map[net.get_shape()[-1].value] = net\n",
    "        print('Encoding step 0 shape {:s}'.format(net.shape))  \n",
    "\n",
    "        net = slim.max_pool3d (net,              2, scope='maxpool0')    \n",
    "        # encoding steps\n",
    "        for step in range(num_contraction):\n",
    "            num_outputs = base_filter * (2**(step+1))\n",
    "            stride = 2\n",
    "            if step == 0: stride = 1\n",
    "            net = double_toy_resnet(net, num_outputs, trainable=trainable, stride=stride, scope='res{:d}'.format(step+1))\n",
    "            conv_feature_map[net.get_shape()[-1].value] = net\n",
    "            print('Encoding step {:d} shape {:s}'.format(step+1,net.shape))\n",
    "        # decoding steps\n",
    "        for step in range(num_contraction):\n",
    "            num_outputs = net.get_shape()[-1].value / 2\n",
    "            net = slim.conv3d_transpose(net, num_outputs, 3, stride=2, normalizer_fn=slim.batch_norm, trainable=trainable, scope='deconv{:d}'.format(step))\n",
    "            net = tf.concat([net, conv_feature_map[num_outputs]], axis=len(net.shape)-1, name='concat{:d}'.format(step))\n",
    "            net = double_toy_resnet(net, num_outputs, trainable=trainable, scope='conv{:d}'.format(step+num_contraction+1))\n",
    "            print('Decoding {:d} shape {:s}'.format(step,net.shape))\n",
    "\n",
    "        # final conv layer\n",
    "        net = slim.conv3d(net, num_class, 3, normalizer_fn=slim.batch_norm, trainable=trainable, scope='lastconv')\n",
    "        print('Final shape {:s}'.format(net.shape))  \n",
    "        return net\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building train net...\n",
      "Input shape (?, 192, 192, 192, 1)\n",
      "Encoding step 0 shape (?, 192, 192, 192, 8)\n",
      "Encoding step 1 shape (?, 96, 96, 96, 16)\n",
      "Encoding step 2 shape (?, 48, 48, 48, 32)\n",
      "Encoding step 3 shape (?, 24, 24, 24, 64)\n",
      "Encoding step 4 shape (?, 12, 12, 12, 128)\n",
      "Decoding 0 shape (?, 24, 24, 24, 64)\n",
      "Decoding 1 shape (?, 48, 48, 48, 32)\n",
      "Decoding 2 shape (?, 96, 96, 96, 16)\n",
      "Decoding 3 shape (?, 192, 192, 192, 8)\n",
      "Final shape (?, 192, 192, 192, 3)\n",
      "\n",
      "Building test net...\n",
      "Input shape (?, 192, 192, 192, 1)\n",
      "Encoding step 0 shape (?, 192, 192, 192, 8)\n",
      "Encoding step 1 shape (?, 96, 96, 96, 16)\n",
      "Encoding step 2 shape (?, 48, 48, 48, 32)\n",
      "Encoding step 3 shape (?, 24, 24, 24, 64)\n",
      "Encoding step 4 shape (?, 12, 12, 12, 128)\n",
      "Decoding 0 shape (?, 24, 24, 24, 64)\n",
      "Decoding 1 shape (?, 48, 48, 48, 32)\n",
      "Decoding 2 shape (?, 96, 96, 96, 16)\n",
      "Decoding 3 shape (?, 192, 192, 192, 8)\n",
      "Final shape (?, 192, 192, 192, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Building train net...')\n",
    "train_net = toy_uresnet (images3D, 3, trainable=True,  reuse=False, base_filter=8, num_contraction=4)\n",
    "\n",
    "print('\\nBuilding test net...')\n",
    "test_net  = toy_uresnet (images3D,  3, trainable=False, reuse=True, base_filter=8, num_contraction=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 192, 192, 192, 3)\n",
      "(?, 192, 192, 192)\n",
      "(?, 192, 192, 192)\n",
      "(?,)\n",
      "(?, 192, 192, 192, 3)\n",
      "(?, 3)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('analysis'):\n",
    "    prediction     = tf.argmax(test_net,4)\n",
    "    accuracy_allpx = tf.reduce_mean(tf.cast(tf.equal(prediction, labels),tf.float32))\n",
    "    nonzero_idx    = tf.where(tf.reshape(images, [-1, 192, 192, 192]) > tf.to_float(0.) )\n",
    "    nonzero_label  = tf.gather_nd(labels, nonzero_idx)\n",
    "    nonzero_pred   = tf.gather_nd(tf.argmax(test_net, 4), nonzero_idx)\n",
    "    accuracy_valpx = tf.reduce_mean(tf.cast(tf.equal(nonzero_label, nonzero_pred),tf.float32))\n",
    "    softmax        = tf.nn.softmax(logits=test_net)\n",
    "    \n",
    "    nonzero_softmax = tf.gather_nd(softmax,nonzero_idx)\n",
    "    \n",
    "\n",
    "print np.shape(test_net)\n",
    "print np.shape(prediction)\n",
    "print np.shape(labels)\n",
    "print np.shape(nonzero_label)\n",
    "print np.shape(softmax)\n",
    "print np.shape(nonzero_softmax)\n",
    "with tf.variable_scope('train'):\n",
    "    loss_pixel     = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=train_net)\n",
    "    loss_weighted  = tf.multiply(loss_pixel, weights)\n",
    "    loss           = tf.reduce_mean(tf.reduce_sum(tf.reshape(loss_weighted, [-1, int(192**3)]),axis=1))\n",
    "    learning_rate  = tf.placeholder(tf.float32,[])\n",
    "    train          = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /u/gl/tedeschi/phase1/9-05-1_zero_weights-13000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 192, 192)\n",
      "(1099, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 192, 192)\n",
      "(1014, 4)\n",
      "INFO:tensorflow:Restoring parameters from /u/gl/tedeschi/phase1/9-05-1_zero_weights-14000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 192, 192)\n",
      "(1099, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 192, 192)\n",
      "(1014, 4)\n",
      "INFO:tensorflow:Restoring parameters from /u/gl/tedeschi/phase1/9-05-1_zero_weights-15000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 192, 192)\n",
      "(1099, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 192, 192)\n",
      "(1014, 4)\n",
      "INFO:tensorflow:Restoring parameters from /u/gl/tedeschi/phase1/9-05-1_zero_weights-16000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 192, 192)\n",
      "(1099, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 192, 192)\n",
      "(1014, 4)\n",
      "INFO:tensorflow:Restoring parameters from /u/gl/tedeschi/phase1/9-05-1_zero_weights-17000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 192, 192)\n",
      "(1099, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 192, 192, 192)\n",
      "(1014, 4)\n"
     ]
    }
   ],
   "source": [
    "#sess = tf.Session()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "#reader = tf.train.Saver(tf.get_collection(tf.GraphKeys.MODEL_VARIABLES))\n",
    "\n",
    "#for j in range(13,18):\n",
    " #   reader.restore(sess, './9-05-1_zero_weights-'+str(j*1000))\n",
    "\n",
    " #   fout=open('9-05-1_zero_weights-{}.csv'.format(j*1000),'w')\n",
    " #   fout.write('entry,accuracy\\n')\n",
    " #   for i in range(2):\n",
    " #       X_train, y_train, w_train = read_events(start_index=i, end_index=i+1)\n",
    "        #print('test accuracy on non-zero pixels%g' % sess.run(accuracy_valpx, feed_dict={images: X_train, labels: y_train, weights: w_train}))\n",
    " #       acc,soft=sess.run([accuracy_valpx,nonzero_softmax], feed_dict={images: X_train, labels: y_train, weights: w_train})\n",
    "        \n",
    "        #accuracy[i]=acc\n",
    "        #fout.write('entry,accuracy\\n')\n",
    " #       entry = i\n",
    " #       accuracy = float(acc)\n",
    "  #      fout.write('%d,%g' % (entry,accuracy))\n",
    "  #      fout.write('\\n')\n",
    "  #  fout.close()\n",
    "    #imshow_test(16,X_train,y_train,w_train)\n",
    "    #print np.mean(accuracy)\n",
    "    \n",
    "    \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "reader = tf.train.Saver(tf.get_collection(tf.GraphKeys.MODEL_VARIABLES))\n",
    "\n",
    "for j in range(13,18):\n",
    "    reader.restore(sess, '/u/gl/tedeschi/phase1/9-05-1_zero_weights-'+str(j*1000))\n",
    "\n",
    "    fout=open('9-05-1_zero_weights-{}.csv'.format(j*1000),'w')\n",
    "    fout.write('entry,accuracy,softmax\\n')\n",
    "    for i in range(2):\n",
    "        X_train, y_train, w_train = read_events(start_index=i, end_index=i+1)\n",
    "        #print('test accuracy on non-zero pixels%g' % sess.run(accuracy_valpx, feed_dict={images: X_train, labels: y_train, weights: w_train}))\n",
    "        \n",
    "        acc,soft,nonzero_idxx=sess.run([accuracy_valpx,softmax,nonzero_idx], feed_dict={images: X_train, labels: y_train, weights: w_train})\n",
    "        result = np.zeros(y_train.shape,dtype=np.float32)\n",
    "        #print np.shape(result)\n",
    "        #print np.shape(soft)\n",
    "        for class_label in range(1,3):\n",
    "            class_mask = np.where(y_train==class_label)\n",
    "            result[class_mask] = (soft[:,:,:,:,class_label])[class_mask] \n",
    "        \n",
    "        print np.shape(X_train)\n",
    "        #nonzero_idxx=np.where(X_train > 0.)\n",
    "        #print np.shape(result)\n",
    "        print np.shape(nonzero_idxx)\n",
    "        result=np.take(result,nonzero_idxx)\n",
    "        #accuracy[i]=acc\n",
    "        #fout.write('entry,accuracy\\n')\n",
    "        entry = i\n",
    "        accuracy = float(acc)\n",
    "        s = result.mean()\n",
    "        fout.write('%d,%g,%g' % (entry,accuracy,s))\n",
    "        fout.write('\\n')\n",
    "    fout.close()\n",
    "    #imshow_test(16,X_train,y_train,w_train)\n",
    "    #print np.mean(accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry 0 accuracy 0.9208370000000001 softmax 0\n",
      "entry 1 accuracy 0.9270219999999999 softmax 0\n",
      "\n",
      "Mean accuracy 0.9239295000000001\n",
      "Mean Softmax 0.0\n",
      "\n",
      "entry 0 accuracy 0.938126 softmax 0\n",
      "entry 1 accuracy 0.977318 softmax 0\n",
      "\n",
      "Mean accuracy 0.957722\n",
      "Mean Softmax 0.0\n",
      "\n",
      "entry 0 accuracy 0.939945 softmax 0\n",
      "entry 1 accuracy 0.9497040000000001 softmax 0\n",
      "\n",
      "Mean accuracy 0.9448245000000001\n",
      "Mean Softmax 0.0\n",
      "\n",
      "entry 0 accuracy 0.938126 softmax 0\n",
      "entry 1 accuracy 0.935897 softmax 0\n",
      "\n",
      "Mean accuracy 0.9370115\n",
      "Mean Softmax 0.0\n",
      "\n",
      "entry 0 accuracy 0.9390350000000001 softmax 0\n",
      "entry 1 accuracy 0.897436 softmax 0\n",
      "\n",
      "Mean accuracy 0.9182355\n",
      "Mean Softmax 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "ac=np.zeros(5)\n",
    "so=np.zeros(5)\n",
    "for j in range(13,18):\n",
    "\n",
    "    df = pd.read_csv('9-05-1_zero_weights-{}.csv'.format(j*1000),dtype={'accuracy': float})\n",
    "\n",
    "    for x in range(df.entry.size):\n",
    "        print 'entry',df.entry.values[x],'accuracy',df.accuracy.values[x], 'softmax', df.softmax.values[x]\n",
    "    print\n",
    "    ac[j-13]=df.accuracy.values.mean()\n",
    "    so[j-13]=df.softmax.values.mean()\n",
    "    \n",
    "    print 'Mean accuracy', df.accuracy.values.mean()\n",
    "    print 'Mean Softmax', df.softmax.values.mean()\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efdb20baa50>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fig,ax1=plt.subplots(figsize=(12,8),facecolor='w')\n",
    "#ax1.plot(np.arange(0,5,ac,linewidth=2,label='Loss',color='b')\n",
    "#ax1.set_xlabel('Iterations',fontweight='bold',fontsize=24,color='black')\n",
    "#ax1.tick_params('x',colors='black',labelsize=18)\n",
    "#ax1.set_ylabel('Non-zero pixel accuracy', fontsize=24, fontweight='bold',color='b')\n",
    "#ax1.tick_params('y',colors='b',labelsize=18)\n",
    "\n",
    "#ax2 = ax1.twinx()\n",
    "#ax2.plot(0,5,so,color='r',label='Softmax')\n",
    "#ax2.set_ylabel('Softmax', fontsize=24, fontweight='bold',color='r')\n",
    "#ax2.tick_params('y',colors='r',labelsize=18)\n",
    "#ax2.set_ylim(0.,0.2)\n",
    "\n",
    "#plt.grid()\n",
    "#plt.show()\n",
    "\n",
    "plt.plot([1,2,3,4,5],ac)\n",
    "plt.plot([1,2,3,4,5],so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
